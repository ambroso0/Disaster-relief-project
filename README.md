# Disaster-relief-project

In early 2010 Haiti was hit by a magnitude 7.0 earthquake. This catastrophe leveled many buildings, and resulted in numerous lives lost. In the wake of the earthquake, more than 50% of the population at the time, were displaced, with 1.5 million of them living in tent camps. This wide-spread displacement of people across the island, made relief efforts more difficult. 
In this scenario, we are working towards developing a predictive model which will help locating displaced people using RGB data extracted from aerial imagery of the country. It was known that displaced people were using blue tarp to create tent to shelter them. This distinguishable blue color was used to facilitate the identification of displaced people through aerial images.  For this purpose, we have a data set of RGB values and categorical variables denoting the structure types present in the images.  This dataset will be used to develop a model that has a high detection rate regarding true positives in order to maximize its capability to save lives in a precise manner. We will consider the accuracy and the False Negative Rate (FNR) and False Positive Rate (FPR) as metrics to determine the performance of the model selected. In particular the FPR has the potential to draw false conclusion and to jeopardize the rescue efforts in a context where time is the essence in terms of saving lives. 

# Project details

The objective of this disaster relief initiative is to assess the performance of various algorithms when applied to imagery data collected during the 2010 earthquake relief efforts in Haiti. The primary aim is to identify the most accurate and timely method for locating as many displaced individuals as possible, based on the imagery data. 
This project evaluates the effectiveness of several algorithms, including Logistic Regression, Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), K-Nearest Neighbor (KNN), Penalized Logistic Regression, Random Forest, and Support Vector Machines (SVM). The evaluation is carried out using 10-fold cross-validation and a separate hold-out dataset. The dataset used for this analysis is sourced from the 'HaitiPixels.csv' file, which consists of three columns: 'Class', 'Red', 'Green', and 'Blue'. The 'Red', 'Green', and 'Blue' columns contain pixel data collected at various locations, while the 'Class' column categorizes objects found in the images, classifying them as 'vegetation', 'soil', 'rooftop', 'various non-tarp', or 'blue tarp'. In this project, the 'blue tarp' category from the 'Class' column serves as the response or outcome variable, while 'Red', 'Green', and 'Blue' are used as predictor variables. This dataset is utilized to assess the performance of the five different algorithms and identify the most effective one for predicting the presence of blue tarps.

# Cross-validation performance table
![image](https://github.com/ambroso0/Disaster-relief-project/assets/38117605/e2364858-9914-4b74-828e-9a85f3354071)

In this analysis, all the classification methods displayed remarkable effectiveness in categorizing blue tarp pixels based on their RGB values during training via 10-fold cross-validation. The performance of the logistic regression and penalized logistic regression models was quite similar, which is logical given that the optimal lambda value was zero, implying no significant predictor reduction.
However, the discriminant analysis (LDA/QDA) models lagged behind the top-performing models, particularly in terms of specificity and FDR. Among all the models, the LDA model exhibited the highest False Positive Rate (FPR) and the lowest accuracy. On the other hand, the K-Nearest Neighbor (KNN) model showcased one of the highest accuracy values and the lowest FPR.

Upon scrutinizing the data table, it became evident that Random Forest (RF) emerged as the most promising option. The RF model boasted the highest accuracy and the lowest FPR. It's important to note that the metrics for RF were computed without employing a test dataset. The true potential of RF for blue tarp classification will be assessed when testing the model against the hold-out dataset.

# A discussion of the relevance of the metrics calculated in the tables to this application context

As seen in some of the models, accuracy could be a misleading metric in the fact that high accuracy, the percentage of predictions that are correct, does not guarantee we will be able to effectively achieve a good model for our application. This is especially true for this project, where achieving a high true positive rate is paramount to successfully identify the highest number of displaced people as possible. The other issue with using accuracy as a metric is that we have a highly imbalanced dataset leading to the fact that as we change the threshold to maximize the TPR we risk increasing the number of false positives predicted by the model.
The area under the curve (AUC) quantifies how well a model can differentiate between classes. When combined with other metrics, such as Precision and Sensitivity, it is a valuable metric to determine the performance of the model.
Despite ROC and threshold are not a direct measure of the performance of the model, they could provide insights and help adjust other metrics. The ROC curve is generated by reported performance metrics (TPR and FPR) at different threshold values. Thresholds set the decision point to determine which class an observation is assigned to. The prediction function produces a probability that is compared to the threshold value and then a class is assigned. By adjusting the threshold, we can maximize a metric such as the TPR.
Recall/Sensitivity explains how many of the actual positive cases we were able to predict correctly with our model. It is useful when the FNR is of higher concern than the FPR. Therefore, it is a measure the percentage of blue tarps weâ€™ve identified of all the blue tarps that are there to be identified. Considering our goal is to correctly identify blue tarp, recall is a fundamental metric to consider in selecting the best performance model.


*Full report and code can be provided upon request. 
